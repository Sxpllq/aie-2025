# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк, 9 столбцов (в файле есть `sample_id` + 8 признаков; в DataFrame после `index_col='sample_id'` размер (12000, 8))
- Признаки: все признаки числовые (`float64`)
- Пропуски: нет (во всех колонках Non-Null Count = 12000)
- "Подлости" датасета: разные шкалы признаков + выраженная ненормальность/тяжёлые хвосты у части признаков (потенциальные выбросы), что критично для distance-based методов без корректного scaling

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 строк, 4 столбца (`sample_id` + 3 признака; в DataFrame размер (8000, 3))
- Признаки: все признаки числовые (`float64`)
- Пропуски: нет (во всех колонках Non-Null Count = 8000)
- "Подлости" датасета: нелинейная/сложная структура и неоднородность распределений (в т.ч. тяжёлые хвосты по одному из признаков) + шумовой признак `z_noise`

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15000 строк, 5 столбцов (`sample_id` + 4 признака; в DataFrame размер (15000, 4))
- Признаки: все признаки числовые (`float64`)
- Пропуски: нет (во всех колонках Non-Null Count = 15000)
- "Подлости" датасета: сложная структура с различной плотностью кластеров + фоновый шум, а также коррелированный признак (`f_corr`), что может ухудшать работу методов, чувствительных к локальной плотности (DBSCAN)

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

### Выбор масштабирования признаков (препроцессинг)

Для каждого датасета масштабирование признаков подбиралось **осознано**, на основе проведенных тестов.
Выбор алгоритма масштабирования важно для корректной работе моделей кластеризации на основе расстояний между объектами.

Были выбранны следующие критерии выбора масштабирования:
- **Асиметрия** (skewness): отражает перекос распределния. Если асиметрия больше 1 или меньше -1, то распределение считается сильно асимметричным.
- **Куртозис** (kurtosis_excess): отражает "островершинность" распределения. Если куртозис больше 3, то распределение считается острое.
- **Тест Андерсона-Дарлинга** (Anderson-Darling test): статистический тест на нормальность распределения. Чем меньше значение статистики, тем больше вероятность того, что выборка взята из нормального распределения.

При больших данных (наш случай, 8k-15k строк) p-значение классических тестов на нормальность (Шапиро-Уилка, Агостино-Пирсона) всегда будет близко к нулю, поэтому они были отброшены при рассмотрения и остались только для обратной совместимости.

Логика выбора масштабирования следующая:
- Для RobustScaler: если существенно отклоняется от нормально распределения, обладает тяжелами хвостами или плоской формой, потенциально содержит выбросы. RobustScaler устойчив к выбросам и не зависит от параметров распределения.
- Для StandardScaler: если данные примерно нормально распределены, без значительных выбросов. StandardScaler центрирует данные и масштабирует их до единичной дисперсии, что полезно для алгоритмов, предполагающих нормальное распределение.

Для каждого датасета были получены следующие результаты тестов и выбран соответствующий метод масштабирования признаков:
- dataset-01: RobustScaler для колонок `f01`, `f02`, `f03`, `f04`, `f05`, `f06`. StandardScaler для колонок `f07`, `f08`.
- dataset-02: RobustScaler для колонок `x1`, `x2`. StandardScaler для колонок `z_noise`.
- dataset-03: RobustScaler для колонок `x1`, `x2`, `f_corr`. StandardScaler для колонок `f_noise`.

На удивление, в датасетах нет пропусков, поэтому иммутация фактически не влияла на данные, однако в пайплайне задействован `SimpleImputer(strategy="median")` как часть универсального и воспроизводимого препроцессинга.

PCA применялась **только для визуализации** (PCA(2D) scatter с раскраской по кластерам), а не как этап обучения моделей кластеризации.

Энкодинг категориальных признаков не применялся, так как в выбранных датасетах категориальных признаков нет.

### Поиск гиперпараметров моделей

Для каждого датасета параметры подбирались перебором по сетке:

- KMeans: перебор `k` по списку значений из конфигурации; `random_state` фиксирован (=42).  
  Лучший `k` выбирался по максимальному `silhouette_score` среди проверенных значений.

- DBSCAN: перебор по сетке `(eps, min_samples)`; дополнительно фиксировались:
  - доля шума `noise_frac` (доля меток `-1`),
  - число кластеров (без шума).

Лучший набор параметров DBSCAN выбирался по максимальному `silhouette_score` **среди валидных конфигураций** (метрики считаются только если среди non-noise точек получается ≥2 кластера).

### Метрики

Для каждой модели считались внутренние метрики качества:
- `silhouette_score` (больше — лучше),
- `davies_bouldin_score` (меньше — лучше),
- `calinski_harabasz_score` (больше — лучше).

Для DBSCAN метрики считались по non-noise точкам (labels != -1), и отдельно фиксировалась доля шума `noise_frac`.

### Визуализация

Для каждого датасета строились:
- график подбора параметров KMeans: `silhouette` vs `k` (и дополнительно `inertia` vs `k`),
- PCA(2D) scatter для лучшего решения KMeans,
- PCA(2D) scatter для лучшего решения DBSCAN (с учётом шума `-1`).

Все изображения сохранялись в `artifacts/figures/<dataset_name>/` относительными путями.

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Для каждого из трёх датасетов сравнивались:

- KMeans:
  - подбирали `k`,
  - фиксировали `random_state=42`,
  - использовали `n_init="auto"` (с fallback на `n_init=10` для совместимости версий sklearn).

- DBSCAN:
  - подбирали `eps`, `min_samples`,
  - отдельно анализировали долю шума (`label = -1`) и число кластеров без шума.

AgglomerativeClustering не использовался (основное сравнение выполнено между KMeans и DBSCAN).

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: DBSCAN, `eps=0.8`, `min_samples=20`
- Метрики (silhouette / DB / CH):
  - silhouette: 0.323
  - Davies-Bouldin: 1.344
  - Calinski-Harabasz: 6964.0
- Если был DBSCAN: доля шума и комментарий
  - noise_frac: 0.014 (≈1.4% точек помечены шумом)
  - кластеры (без шума): 4
- Коротко: почему это решение выглядит разумным именно для этого датасета  
  Dataset-01 содержит сложную структуру и потенциальные выбросы/хвосты. DBSCAN в данном случае лучше “снимает” плотностные группы и допускает небольшой шум, тогда как KMeans (лучший k=2, silhouette≈0.29) даёт более грубое разбиение.

### 4.2 Dataset B

- Лучший метод и параметры: KMeans, `k=2`
- Метрики (silhouette / DB / CH):
  - silhouette: 0.521
  - Davies-Bouldin: 0.647
  - Calinski-Harabasz: 13198.0
- Если был DBSCAN: доля шума и комментарий
  - при `eps=0.5` и разных `min_samples` silhouette оказался отрицательным (лучшее значение: -0.299), что является признаком неудачной кластеризации DBSCAN для данной структуры данных
- Коротко: почему это решение выглядит разумным именно для этого датасета  
  Dataset-02 хорошо разделяется на две группы в геометрическом смысле, что согласуется с предпосылками KMeans. DBSCAN не демонстрирует устойчивой плотностной кластерной структуры и даёт отрицательный silhouette.

### 4.3 Dataset C

- Лучший метод и параметры: KMeans, `k=12` (выбран по silhouette среди проверенных)
- Метрики (silhouette / DB / CH):
  - KMeans: silhouette 0.211, Davies-Bouldin 1.517, Calinski-Harabasz 6526.9
  - DBSCAN (лучшая валидная конфигурация): `eps=0.5`, `min_samples=3` → silhouette 0.208, Davies-Bouldin 0.65, Calinski-Harabasz 10.2, noise_frac 0.004, clusters=3
- Если был DBSCAN: доля шума и комментарий
  - noise_frac: 0.004 (шум крайне мал)
  - однако результаты DBSCAN оказались чувствительны к небольшим изменениям гиперпараметров (см. раздел устойчивости)
- Коротко: почему это решение выглядит разумным именно для этого датасета  
  Dataset-03 является сложным (разная плотность + шум), поэтому оба метода показывают относительно низкий silhouette. KMeans выбран как более воспроизводимое решение (проверка устойчивости показывает высокую согласованность разбиений при подвыборках), тогда как DBSCAN демонстрирует высокую чувствительность к eps/min_samples.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans “ломается” (или даёт слишком грубое/неинтерпретируемое разбиение), когда структура кластеров не является близкой к “шарообразной” и/или присутствуют выбросы и неоднородные хвосты распределений. Это было заметно на dataset-01 (KMeans дал лучшее решение при k=2, но с меньшим silhouette, чем у DBSCAN) и на dataset-03 (рост k до 12 помогает по silhouette, но структура остаётся сложной).
- DBSCAN выигрывает там, где присутствуют плотностные “островки” и допустим шум/выбросы: на dataset-01 DBSCAN дал более высокое значение silhouette и разумную долю шума.
- DBSCAN проигрывает на данных без выраженной плотностной структуры и при близко-равномерной плотности: на dataset-02 silhouette оказался отрицательным даже для “лучшей” конфигурации, что указывает на несоответствие предпосылок DBSCAN структуре данных.
- Самый сильный фактор, влияющий на результаты: масштабирование признаков (особенно при наличии разных распределений и хвостов) и плотностная неоднородность (ключевая причина нестабильности DBSCAN на dataset-03).

### 5.2 Устойчивость (обязательно для одного датасета)

Проверка устойчивости выполнялась для dataset-03.

1) **Устойчивость KMeans к подвыборкам данных.**  
Для KMeans с k=12 было сделано 5 запусков на случайных подвыборках по 80% объектов. Сходство разбиений оценивалось ARI на пересечениях подвыборок. Получено:
- silhouette на подвыборках: mean=0.284 ± 0.002 (качество стабильное),
- ARI: mean=0.797, min=0.668, max=0.932 (разбиения в целом согласованы и воспроизводимы).

Вывод: разбиение KMeans является устойчивым к изменению состава данных (подвыборкам).

2) **Чувствительность DBSCAN к гиперпараметрам.**  
Для DBSCAN исследована локальная окрестность параметров вокруг базовой точки (`eps=0.5`, `min_samples=3`). Результаты показали, что небольшие изменения параметров приводят к резким изменениям числа кластеров (от 2 до 46) и сильным колебаниям silhouette (в среднем 0.018 ± 0.229), вплоть до схлопывания решения в один кластер при увеличении eps.

Вывод: DBSCAN неустойчив на dataset-03 и чувствителен к параметрам, что согласуется со сложной структурой данных (разная плотность кластеров).

### 5.3 Интерпретация кластеров

Интерпретация выполнялась качественно на основе PCA(2D)-проекций и характера разделения:

- Dataset-01: DBSCAN выявляет несколько отчётливых групп (4 кластера) и небольшой шум; это согласуется с предположением о плотностных структурах и наличии выбросов/нетипичных точек.
- Dataset-02: KMeans формирует два устойчиво разделённых кластера, что указывает на доминирующее глобальное разделение данных (подходящее для KMeans).
- Dataset-03: чёткая интерпретация затруднена из-за низкой разделимости (низкий silhouette). KMeans даёт более детализированное разбиение (k=12), при этом оно воспроизводимо (устойчиво к подвыборкам). DBSCAN фиксирует небольшое число плотностных групп, но решение сильно зависит от параметров.

## 6. Conclusion

- Масштабирование критично для distance-based кластеризации: без него геометрия расстояний и качество кластеров существенно искажаются.
- Для признаков с тяжёлыми хвостами/отклонением от нормальности RobustScaler даёт более устойчивое поведение по сравнению со StandardScaler.
- KMeans хорошо работает на задачах с “глобально” разделимыми, близкими к компактным кластерами (dataset-02).
- DBSCAN полезен для плотностной структуры и выбросов/шума (dataset-01), но может полностью проигрывать на данных без явных плотностных кластеров (dataset-02).
- На сложных данных с разной плотностью (dataset-03) результаты обоих методов могут быть ограничены; важно анализировать не только метрики, но и устойчивость.
- Проверки устойчивости (subsampling + ARI, чувствительность к параметрам) позволяют отличать “случайное” улучшение метрик от воспроизводимого решения.
- PCA(2D) следует трактовать как инструмент визуальной интерпретации, а не как доказательство качества кластеризации.
